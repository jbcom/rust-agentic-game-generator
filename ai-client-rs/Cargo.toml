[package]
name = "ai-client-rs"
version = "0.1.0"
authors = ["Jon Bogaty <jon@jonbogaty.com>"]
edition = "2024"
rust-version = "1.85"
license = "MIT OR Apache-2.0"
description = "Multi-provider AI abstraction for Rust - OpenAI, Anthropic with caching"
keywords = ["ai", "openai", "anthropic", "llm", "cache"]
categories = ["api-bindings", "caching"]
repository = "https://github.com/jbcom/rust-ai-client"
homepage = "https://github.com/jbcom/rust-ai-client"

[workspace]

[dependencies]
# Core async runtime
tokio = { version = "1.48", features = ["full"] }
async-trait = "0.1"
futures = "0.3"
tokio-stream = { version = "0.1", features = ["fs"] }

# OpenAI API client
async-openai = { version = "0.32", features = ["full"] }

# Error handling
anyhow = "1.0"
thiserror = "2.0"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
bincode = "1.3"

# HTTP client
reqwest = { version = "0.12", features = ["json", "stream"] }
reqwest-middleware = "0.4"

# Token counting
tiktoken-rs = "0.7"

# Caching and utilities
sha2 = "0.10"
zstd = "0.13"
image = "0.25"
base64 = "0.22"
dirs = "6.0"
chrono = { version = "0.4", features = ["serde"] }
uuid = { version = "1.19", features = ["v4"] }
regex = "1.11"

# Logging
tracing = "0.1"

# Template engine
minijinja = { version = "2.14", features = ["loader", "preserve_order"] }

[dev-dependencies]
dotenv = "0.15"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
